{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMqqTkmP+dIk34zsryQJfhz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssooniunnie/reinforcement_scheduling/blob/main/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQjfG_rBd2p_",
        "outputId": "dac617c4-213e-4f2c-b39c-8377dbb88056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install gym\n",
        "!pip install keras\n",
        "!pip install keras-rl2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EUmzCFoD_cco",
        "outputId": "c8720864-94bb-4438-9d74-8612c727a8af"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==2.3.0\n",
            "  Downloading tensorflow-2.3.0-cp38-cp38-manylinux2010_x86_64.whl (320.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 320.5 MB 1.5 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.51.1)\n",
            "Collecting scipy==1.4.1\n",
            "  Downloading scipy-1.4.1-cp38-cp38-manylinux1_x86_64.whl (26.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 26.0 MB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (3.19.6)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.9.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.14.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (3.3.0)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (2.1.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (0.38.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.3.0) (1.6.3)\n",
            "Collecting h5py<2.11.0,>=2.10.0\n",
            "  Downloading h5py-2.10.0-cp38-cp38-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 67.8 MB/s \n",
            "\u001b[?25hCollecting numpy<1.19.0,>=1.16.0\n",
            "  Downloading numpy-1.18.5-cp38-cp38-manylinux1_x86_64.whl (20.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.6 MB 1.2 MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.4.0,>=2.3.0\n",
            "  Downloading tensorflow_estimator-2.3.0-py2.py3-none-any.whl (459 kB)\n",
            "\u001b[K     |████████████████████████████████| 459 kB 72.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.8.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow==2.3.0) (3.2.2)\n",
            "Installing collected packages: numpy, tensorflow-estimator, scipy, h5py, gast, tensorflow\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.7.3\n",
            "    Uninstalling scipy-1.7.3:\n",
            "      Successfully uninstalled scipy-1.7.3\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xarray-einstats 0.3.0 requires numpy>=1.19, but you have numpy 1.18.5 which is incompatible.\n",
            "xarray-einstats 0.3.0 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "tifffile 2022.10.10 requires numpy>=1.19.2, but you have numpy 1.18.5 which is incompatible.\n",
            "tables 3.7.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires numpy>=1.19.0, but you have numpy 1.18.5 which is incompatible.\n",
            "plotnine 0.8.0 requires scipy>=1.5.0, but you have scipy 1.4.1 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jaxlib 0.3.25+cuda11.cudnn805 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "jax 0.3.25 requires numpy>=1.20, but you have numpy 1.18.5 which is incompatible.\n",
            "jax 0.3.25 requires scipy>=1.5, but you have scipy 1.4.1 which is incompatible.\n",
            "cmdstanpy 1.0.8 requires numpy>=1.21, but you have numpy 1.18.5 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.3.3 h5py-2.10.0 numpy-1.18.5 scipy-1.4.1 tensorflow-2.3.0 tensorflow-estimator-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.8/dist-packages (0.25.2)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.5.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.8/dist-packages (from gym) (4.13.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.8/dist-packages (from gym) (1.18.5)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym) (0.0.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.8.0->gym) (3.11.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.8/dist-packages (2.9.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras-rl2\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 722 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow in /usr/local/lib/python3.8/dist-packages (from keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.6.3)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (2.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (3.3.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.14.1)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (0.3.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (3.19.6)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.4.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (2.1.1)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (2.9.1)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.18.5)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.51.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (0.38.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (1.1.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow->keras-rl2) (2.3.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (57.4.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (5.2.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow->keras-rl2) (3.2.2)\n",
            "Installing collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from gym import Env\n",
        "from gym.spaces import Discrete, Box\n",
        "\n",
        "import ast\n",
        "\n",
        "from gym.vector.utils import spaces\n"
      ],
      "metadata": {
        "id": "Uy-TOuXNe1N-"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab/강화학습/data.csv')"
      ],
      "metadata": {
        "id": "hxvnDTzAebEL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MINIMUM_DAY_OFFS = 9\n",
        "\n",
        "\n",
        "class Pilot:\n",
        "    def __init__(self, pilot_id):\n",
        "        self.result = 0\n",
        "        self.plans = []\n",
        "        self.schedule_map = [0] * 30\n",
        "        self.pilot_id = pilot_id\n",
        "  \n",
        "\n",
        "    def get_pilot_id(self):\n",
        "        return self.pilot_id\n",
        "\n",
        "    def get_plans(self):\n",
        "        return self.plans\n",
        "\n",
        "    def get_schedule_map(self):\n",
        "        return self.schedule_map\n",
        "\n",
        "    def apply_plan(self, plan):\n",
        "        if self.is_applicable(plan):\n",
        "            self.plans.append(plan)\n",
        "            self.update_schedule_map(plan)\n",
        "        else:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def is_applicable(self, plan):\n",
        "        # 정책 체크\n",
        "        # 1. 2가 생기면 안됨\n",
        "        if self.is_overlapping(plan):\n",
        "            return False\n",
        "        # 2. 7일에 한번 0이 있어야 한다.\n",
        "        if self.is_overwork_in_week(plan):\n",
        "            return False\n",
        "\n",
        "        # 3. 한 달에 9번 쉬어야 한다.\n",
        "        if self.is_overwork_in_month(plan):\n",
        "            return False\n",
        "\n",
        "        # 모든정첵 통과\n",
        "        return True\n",
        "\n",
        "    def is_overlapping(self, plan):\n",
        "        days_encoding = plan.get_days_encoding()\n",
        "        for index in range(0, len(days_encoding)):\n",
        "            if (days_encoding[index] + self.schedule_map[index]) > 1:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def is_overwork_in_week(self, plan):\n",
        "        start_day_in_window = 0\n",
        "        while (start_day_in_window + 6) <= (len(self.schedule_map) - 1):\n",
        "            total_working_days = 0\n",
        "            for offset in range(0, 7):\n",
        "                current_cursor = start_day_in_window + offset\n",
        "                total_working_days += (self.schedule_map[current_cursor] + plan.get_days_encoding()[current_cursor])\n",
        "            if total_working_days > 6:\n",
        "                return True\n",
        "            start_day_in_window += 1\n",
        "        return False\n",
        "\n",
        "    def is_overwork_in_month(self, plan):\n",
        "        total_working_days_in_month = 0\n",
        "        for i in range(0, len(self.schedule_map)):\n",
        "            total_working_days_in_month += (self.schedule_map[i] + plan.get_days_encoding()[i])\n",
        "\n",
        "        num_day_offs = len(self.schedule_map) - total_working_days_in_month\n",
        "        if num_day_offs < MINIMUM_DAY_OFFS:\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def update_schedule_map(self, plan):\n",
        "        for i in range(0, len(self.schedule_map)):\n",
        "            self.schedule_map[i] += plan.get_days_encoding()[i]\n",
        "\n",
        "    def print_schedule_map(self):\n",
        "        print(\"current scheduel map : \", self.schedule_map)\n",
        "\n",
        "    def print_plan_list(self):\n",
        "        print(\"current plan list : \")\n",
        "        for plan in self.plans:\n",
        "            print(\"    plan id : \", plan.get_plan_id())\n",
        "            print(\"    plan days_encoding : \", plan.get_days_encoding())"
      ],
      "metadata": {
        "id": "dX4x8N47ezsB"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "\n",
        "class Scheduler:\n",
        "    def __init__(self, pilots, plans):\n",
        "        self.pilots = pilots\n",
        "        self.plans = plans\n",
        "        self.num_plans = len(self.plans)\n",
        "        self.num_pilots = len(self.pilots)\n",
        "        self.next_plan = self.get_next_random_plan()\n",
        "\n",
        "    def get_next_plan(self):\n",
        "        return self.next_plan\n",
        "\n",
        "    def get_pilots(self):\n",
        "        return self.pilots\n",
        "\n",
        "    def do_next_deploy(self, pilot_id):\n",
        "        pilot = self.pilots[pilot_id]\n",
        "        result = pilot.apply_plan(self.next_plan)\n",
        "        if not result:\n",
        "            return\n",
        "        self.next_plan = self.get_next_random_plan()\n",
        "        return True\n",
        "\n",
        "    def do_schedule(self):\n",
        "        next_plan = self.get_next_random_plan()\n",
        "        while next_plan is not None:\n",
        "            #########\n",
        "            pilot = self.get_next_random_pilot()\n",
        "            result = pilot.apply_plan(next_plan)\n",
        "            if not result:\n",
        "                return False\n",
        "            #########\n",
        "            next_plan = self.get_next_random_plan()\n",
        "        return True\n",
        "\n",
        "    def get_next_random_pilot(self):\n",
        "        pilot_index = random.randint(0, self.num_pilots - 1)\n",
        "        return self.pilots[pilot_index]\n",
        "\n",
        "    def get_next_random_plan(self):\n",
        "        retry_count = 0\n",
        "        while retry_count < self.num_plans:\n",
        "            candidate_index = random.randint(0, self.num_plans - 1)\n",
        "            # candidate_index 검증\n",
        "            if self.validate_candidate(candidate_index):\n",
        "                self.plans[candidate_index].set_is_applied(True)\n",
        "                return self.plans[candidate_index]\n",
        "            retry_count += 1\n",
        "        return None\n",
        "\n",
        "    def validate_candidate(self, candidate_index):\n",
        "        retrieved_plan = self.plans[candidate_index]\n",
        "        if retrieved_plan.get_is_applied():\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    def print_all_plans_info(self):\n",
        "        pass\n",
        "\n",
        "    def print_all_pilots_info(self):\n",
        "        for pilot in self.pilots:\n",
        "            pilot_id = pilot.get_pilot_id()\n",
        "            plans = pilot.get_plans()\n",
        "            print(\"pilot id : \", pilot_id)\n",
        "            for plan in plans:\n",
        "                print(\"    plan id : \", plan.get_plan_id())\n",
        "                print(\"    plan encoding : \", plan.get_days_encoding())\n"
      ],
      "metadata": {
        "id": "7lW59DzEfNjG"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Plan:\n",
        "    def __init__(self, plan_id, days_encoding, reward):\n",
        "        self.plan_id = plan_id\n",
        "        self.days_encoding = days_encoding\n",
        "        self.is_applied = False\n",
        "        self.reward = reward\n",
        "\n",
        "    def get_plan_id(self):\n",
        "        return self.plan_id\n",
        "\n",
        "    def get_days_encoding(self):\n",
        "        return self.days_encoding\n",
        "\n",
        "    def get_is_applied(self):\n",
        "        return self.is_applied\n",
        "\n",
        "    def set_is_applied(self, is_applied):\n",
        "        self.is_applied = is_applied\n"
      ],
      "metadata": {
        "id": "y9-F80kAfQxj"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_new_scheduler():\n",
        "    # 파일에서 데이터 읽어오기\n",
        "    df = pd.read_csv('/content/drive/MyDrive/Colab/강화학습/data.csv')\n",
        "    # 읽은 파일로 Pilot 리스랑 Plan 트리스트 만들기\n",
        "    pilot_list = []\n",
        "    for i in range(0, 25):\n",
        "        pilot_list.append(Pilot(i))\n",
        "\n",
        "    plan_list = []\n",
        "\n",
        "    plan_id = df.loc[0, 'id']\n",
        "    days_encoding = ast.literal_eval(df.loc[0, 'BLK'])\n",
        "    reward = df.loc[0, 'R']\n",
        "\n",
        "    for i in range(0, len(df)):\n",
        "        plan_id = df.loc[i, 'id']\n",
        "        days_encoding = ast.literal_eval(df.loc[i, 'BLK'])\n",
        "        reward = df.loc[i, 'R']\n",
        "        plan_list.append(Plan(plan_id, days_encoding, reward))\n",
        "\n",
        "    # Pilot이랑 Plan을 생성자로 전달해서 Scheduler 생성\n",
        "    return Scheduler(pilot_list, plan_list)\n",
        "\n",
        "\n",
        "class SchedulingEnvironment(Env):\n",
        "    def __init__(self):\n",
        "        self.scheduler = create_new_scheduler()\n",
        "        self.action_space = Discrete(len(self.scheduler.get_pilots()))\n",
        "        self.observation_space = spaces.Box(low= 0,high =1,\n",
        "                                            shape=(26, 30), dtype=int)\n",
        "        self.state = self.get_observation_data()\n",
        "        \n",
        "\n",
        "    def step(self, action):\n",
        "        result = self.scheduler.do_next_deploy(action)\n",
        "\n",
        "        if result:\n",
        "            reward = 1\n",
        "        else:\n",
        "            reward = -100\n",
        "\n",
        "        next_plan = self.scheduler.get_next_plan()\n",
        "\n",
        "        if next_plan is None:\n",
        "            done = True\n",
        "        else:\n",
        "            done = False\n",
        "\n",
        "        if result is None:\n",
        "            done = True\n",
        "\n",
        "        info = {}\n",
        "\n",
        "        self.state = self.get_observation_data()\n",
        "\n",
        "        return self.state, reward, done, info\n",
        "\n",
        "    def render(self):\n",
        "        pass\n",
        "\n",
        "    def reset(self):\n",
        "        self.scheduler = create_new_scheduler()\n",
        "        self.state = self.get_observation_data()\n",
        "        return self.state\n",
        "\n",
        "    def get_observation_data(self):\n",
        "        result = np.empty((0,30), int)\n",
        "        pilots = self.scheduler.get_pilots()\n",
        "        for pilot in pilots:\n",
        "          schedule = pilot.get_schedule_map()\n",
        "          result = np.append(result, np.array([schedule]), axis=0)\n",
        "\n",
        "        current_plan = self.scheduler.get_next_plan()\n",
        "        days_encoding = current_plan.get_days_encoding()\n",
        "\n",
        "        result = np.append(result, np.array([days_encoding]), axis=0)\n",
        "        return result\n",
        "\n"
      ],
      "metadata": {
        "id": "WdM5wXHWfTIn"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def test_episode():\n",
        "    env = SchedulingEnvironment()\n",
        "    episode = 10\n",
        "    for episode in range(1, episode + 1):\n",
        "        state = env.reset()\n",
        "        done = False\n",
        "        score = 0\n",
        "        while not done:\n",
        "            env.render()\n",
        "            action = random.randint(0, 24)\n",
        "            n_state, reward, done, info = env.step(action)\n",
        "            score += reward\n",
        "        print('Episode:{} Score:{}'.format(episode, score))\n",
        "\n"
      ],
      "metadata": {
        "id": "Uowk2qtqfZFJ"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_episode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "853AoZSQf_Be",
        "outputId": "98ec7291-787b-4959-f085-2883961775a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode:1 Score:-73\n",
            "Episode:2 Score:-33\n",
            "Episode:3 Score:-65\n",
            "Episode:4 Score:-66\n",
            "Episode:5 Score:-25\n",
            "Episode:6 Score:-76\n",
            "Episode:7 Score:-76\n",
            "Episode:8 Score:-85\n",
            "Episode:9 Score:-57\n",
            "Episode:10 Score:-89\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = SchedulingEnvironment()\n",
        "states = env.observation_space.shape\n",
        "actions = env.action_space.n\n"
      ],
      "metadata": {
        "id": "o9HL2vF0g_QV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " obs_shape = env.observation_space.shape\n",
        " print(obs_shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2VcVjteMknq",
        "outputId": "39e25858-3194-49cd-8de3-4e8581e723b6"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(26, 30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n"
      ],
      "metadata": {
        "id": "uagT0NODgUr-"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model"
      ],
      "metadata": {
        "id": "m5xbgt3lKLB3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(24, activation='relu'))\n",
        "model.add(Dense(actions, activation='linear'))\n",
        "\n",
        "model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6Ru511D9cl9",
        "outputId": "dec8fffc-b21d-4934-e252-e935afecbf90"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten_4 (Flatten)          (None, 780)               0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 24)                18744     \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 24)                600       \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 25)                625       \n",
            "=================================================================\n",
            "Total params: 19,969\n",
            "Trainable params: 19,969\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from rl.agents import DQNAgent\n",
        "from rl.policy import BoltzmannQPolicy\n",
        "from rl.memory import SequentialMemory\n"
      ],
      "metadata": {
        "id": "NmUg8jvhnBx1"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_agent(model, actions):\n",
        "    policy = BoltzmannQPolicy()\n",
        "    memory = SequentialMemory(limit=50000, window_length=1)\n",
        "    dqn = DQNAgent(model=model, memory=memory, policy=policy, \n",
        "                  nb_actions=actions, nb_steps_warmup=5, target_model_update=1e-2)\n",
        "    return dqn\n"
      ],
      "metadata": {
        "id": "QnAH5VSI9y5I"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dqn = build_agent(model, actions)\n",
        "dqn.compile(Adam(lr=1e-3), metrics=['mae'])\n",
        "dqn.fit(env, nb_steps=100000, visualize=False, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMTy0Dc49hG4",
        "outputId": "52b3820a-ce98-4405-cd81-07be93555032"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training for 100000 steps ...\n",
            "Interval 1 (0 steps performed)\n",
            "\r    1/10000 [..............................] - ETA: 10:48 - reward: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 5 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   20/10000 [..............................] - ETA: 6:21 - reward: 1.0000"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 6 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.8/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 7 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.8/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 8 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n",
            "/usr/local/lib/python3.8/dist-packages/rl/memory.py:38: DeprecationWarning: This function is deprecated. Please call randint(1, 9 + 1) instead\n",
            "  batch_idxs = np.random.random_integers(low, high - 1, size=size)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000/10000 [==============================] - 153s 15ms/step - reward: -5.9690\n",
            "690 episodes - episode_reward: -86.514 [-99.000, -56.000] - loss: 14438.104 - mae: 232.757 - mean_q: 281.381\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 157s 16ms/step - reward: -7.7466\n",
            "866 episodes - episode_reward: -89.462 [-99.000, -58.000] - loss: 401141.906 - mae: 933.503 - mean_q: 1119.453\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            "10000/10000 [==============================] - 173s 17ms/step - reward: -9.9888\n",
            "1088 episodes - episode_reward: -91.802 [-99.000, -68.000] - loss: 3242328.500 - mae: 1860.596 - mean_q: 2266.024\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 175s 17ms/step - reward: -10.7362\n",
            "1162 episodes - episode_reward: -92.393 [-99.000, -60.000] - loss: 14447834.000 - mae: 3364.415 - mean_q: 4111.002\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 170s 17ms/step - reward: -9.2515\n",
            "1015 episodes - episode_reward: -91.164 [-99.000, -54.000] - loss: 23847508.000 - mae: 3590.400 - mean_q: 4412.481\n",
            "\n",
            "Interval 6 (50000 steps performed)\n",
            "10000/10000 [==============================] - 158s 16ms/step - reward: -7.1002\n",
            "802 episodes - episode_reward: -88.505 [-99.000, -47.000] - loss: 12499424.000 - mae: 1700.081 - mean_q: 2310.797\n",
            "\n",
            "Interval 7 (60000 steps performed)\n",
            "10000/10000 [==============================] - 153s 15ms/step - reward: -5.1105\n",
            "605 episodes - episode_reward: -84.506 [-99.000, -39.000] - loss: 4274874.000 - mae: 1004.331 - mean_q: 1540.843\n",
            "\n",
            "Interval 8 (70000 steps performed)\n",
            "10000/10000 [==============================] - 146s 15ms/step - reward: -3.3733\n",
            "433 episodes - episode_reward: -77.857 [-99.000, -41.000] - loss: 4509144.500 - mae: 1466.675 - mean_q: 2122.545\n",
            "\n",
            "Interval 9 (80000 steps performed)\n",
            "10000/10000 [==============================] - 153s 15ms/step - reward: -3.2723\n",
            "423 episodes - episode_reward: -77.362 [-99.000, -32.000] - loss: 7225502.000 - mae: 3776.576 - mean_q: 4809.708\n",
            "\n",
            "Interval 10 (90000 steps performed)\n",
            "10000/10000 [==============================] - 154s 15ms/step - reward: -3.0602\n",
            "done, took 1592.140 seconds\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcb974a4fa0>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}